---
marp: true
---

## 이 책에서 다루는 내용
1. 스파크 이해하기
    스파크를 전반적으로 소개하고 잡(job)을 다루는 개념을 설명한다.
2. RDD
    PySpark에서 사용하는 스키마가 없는 데이터 구조인 RDD(Resilient Distributed Datasets)를 다룬다.
3. 데이터프레임
    효율 측면에서 스칼라와 파이썬의 격차를 줄이는 데이터 구조를 자세히 살펴본다.
---
4. 데이터 모델링 준비하기
    스파크 환경에서의 데이터 클리닝 혹은 전처리 방법을 제공한다.
5. MLlib 소개하기
    RDD로 작동하는 머신 러닝 라이브러리를 소개하고 가장 많이 사용되는 머신 러닝 라이브러리 사용법을 소개한다.
6. ML 패키지 소개하기
    주류 머신 러닝 라이브러리를 다루고 현재 사용 가능한 모델의 개요를 살펴본다.
---
7. 그래프프레임
    그래프를 이용해 쉽게 풀 수 있는 문제들에 대한 새로운 구조체를 다룬다.
8. 텐서프레임
    스파크와 딥러닝을 연결해주는 텐서프레임을 소개한다.
9. 블레이즈를 이용한 다언어 코드 지속성
    데이터 추상화를 더욱 간단히 하기 위해 스파크에서 블레이즈를 사용할 수 있는 방법을 소개한다.
---
10. 구조적 스트리밍
    PySpark에서 사용 가능한 스트리밍 툴의 개요를 살펴본다.
11. 스파크 애플리케이션 패키지화하기
    작성한 코드를 모듈화하는 방법과 명령어를 통해 모듈을 스파크에서 실행시키는 방법을 다룬다.
---
### 스파크 이해하기
- 스파크는 다양한 종류의 데이터 관련 문제, 예를 들어 반 구조(semi-structed), 구조, 스트리밍 또는 머신러닝/데이터 과학 관련 문제를 해결하기 위해 쉽고 빠르게 쓸 수 있는 프레임워크이다.

--- 
## 이번 장에서 다루는 내용
- 아파치 스파크는 무엇인가?
- 스파크 잡과 API
- RDD(Resilient Distributed Datasets), 데이터프레임, 데이터셋
- 카탈리스트 옵티마이저와 프로젝트 텅스텐
- 스파크 2.0의 구조

---
## 1. 아파치 스파크는 무엇인가?
- 아파치 스파크는 오픈소스 분산 쿼리 및 처리 엔진이다. 스파크는 유연성과 맵리듀스에 대한 확장성을 훨씬 빠른 속도로 제공한다. 데이터가 메모리에 저장되어 있을 때는 아파치 하둡보다 100배 빠르며, 디스크에 저장되어 있을 때는 10배 빠르다.
- 스파크는 데이터를 읽고, 변형하고, 합계를 낼 수 있으며, 복잡한 통계 모델들을 쉽게 학습하고 배포할 수 있다. 
- 스파크 API는 자바, 스칼라, 파이썬, R, SQL을 이용해 접근할 수 있다. 애플리케이션을 배포하는 데 쓰일 수 있고, 여러 애플리케이션을 라이브러리로 묶어서 클러스터에 배포할 수 있으며, 파이썬 노트북을 통해 대화식으로 빠른 분석을 수행할 수 있다.

---
## 1. 아파치 스파크는 무엇인가?
- 스파크는 파이썬 Pandas 라이브러리와 R의 data.frames 또는 data.tablees를 이용하는 데이터 분석가, 데이터 과학자 또는 연구원들에게 적합한 여러 라이브러리를 제공한다.
- 스파크의 데이터프레임은 pandas나 data.frames/data.tables와 유사하지만, 몇 가지 다른 부분도 있으므로 너무 큰 기대는 하지 않는 게 좋다.
- SQL에 익숙한 사용자들은 데이터를 다지기 위해 쿼리를 사용할 수 있다. 또한 몇몇 선구현, 튜닝도니 알고리즘, 통계 모델과 프레임워크를 아파치 스파크로 사용 가능하다.

---
### 1. 아파치 스파크는 무엇인가?
- 머신러닝을 위한 MLlib과 ML 라이브러리, 그래프 처리를 위한 GraphX와 그래프프레임, 스파크 스트리밍(Dstream 스트림과 구조적 스트림)이 해당한다.
- 스파크로 이러한 라이브러리들을 한 애플맄이션에서 균일하게 사용할 수 있다.
- 아파치 스파크는 개인 PC에서도 쉽게 동작하며, YARN과 아파치 메소스(또는 로컬 클러스터나 클라우드)에서 standalone 모드로 쉽게 사용할 수 있다.
- 스파크는 데이터를 HDFS, 아파치 카산드라, 아파치 HBase, S3와 같은 다양한 소스로부터 읽고 쓸 수 있다.

