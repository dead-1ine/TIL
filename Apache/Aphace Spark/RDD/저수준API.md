# 저수준 API

다음과 같은 상황에서 저수준 API를 사용한다.

- 고수준 API에서 제공하지 않는 기능이 필요한 경우. 예를 들어 클러스터의 물리적 데이터의 배치를 아주 세밀하게 제어해야하는 상황에서 필요하다.
- RDD를 사용해 개발된 기존 코드를 유지해야하는 경우
- 사용자가 정의한 공유 변수를 다뤄야할 경우.



위와 같은 상황에서만 저수준 API를 사용하는 것을 권장한다. 그러나 스파크의 모든 워크로드는 저수준 기능을 사용하는 기초적인 형태로 컴파일되므로 이를 이해하는 것은 많은 도움이 될 수 있다.

DataFrame 트랜스포메이션을 호출하면 실제로 다수의 RDD 트랜스포메이션으로 변환된다.

스파크를 잘 알고 있는 숙련된 개발자라 하더라도 구조적 API 위주로 사용하는 것이 좋다. 



## 12.1.2 저수준 API는 어떻게 사용할까

`SparkContext`는 저수준 API 기능을 사용하기 위한 진입 지점이다. 스파크 클러스터에서 연산을 수행하는 데 필요한 도구인 `SparkSession`을 이용해 `SparkContext`에 접근할 수 있다.

다음 명령을 사용해 `SparkContext`에 접근할 수 있다.

```python
spark.sparkContext
```



