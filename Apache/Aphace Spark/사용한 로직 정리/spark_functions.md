# Pyspark에서 사용한 함수를 정리

## from pyspark.sql.functions

- select
- groupBy
- filter, where
- lit
- coalesce
- withColumn
- withColumnRenamed
- cache
- persist
- dropDuplicates
- date_format
- rangeBetween
- when - otherwise
- alias
- drop
- agg
- collect_list
- collect_set
- array_except
- exists
- size
- slice
- astype
- over(Window)



## from pyspark.sql.window

- partitonBy