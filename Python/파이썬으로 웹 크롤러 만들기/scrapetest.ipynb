{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Run BeautifulSoup\n",
    "urlopen()을 임포트하고 html.read()를 호출하여 페이지의 HTML 콘텐츠를 얻었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음과 같이 .read()를 호출하지 않고 urlopen이 반환하는 파일 객체를 바로 사용할 수 도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lxml\n",
    "'지저분한' HTML 코드를 분석할 때 html.parser보다 좀 더 낫다.\n",
    "lxml은 닫히지 않은 태그, 계층 구조가 잘못된 태그 등의 문제를 수정한다.\n",
    "\n",
    "## html5lib\n",
    "널리 쓰이는 구문 분석기이다.\n",
    "lxml과 마찬가지로 잘못 쓰여진 HTML을 수정하고 구문 분석을 시도하는데, lxml보다 다양한 에러를 수정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html.read(), 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(html.read(), 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.3 신뢰할 수 있는 연결과 예외 처리\n",
    "웹은 엉망진창이다. 데이터 형식은 제대로 지켜지지 않고 웹사이트는 자주 다운되며 닫는 태그도 종종 빠져 있다.\n",
    "이런 상황들을 예상하여 예외를 어떻게 처리할지 생각해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이 행에서 문제가 생길 수 있는 부분은 크게 두가지이다.\n",
    "- 페이지를 찾을 수 없거나, URl 해석에 에러가 생긴 경우\n",
    "- 서버를 찾을 수 없는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/error.html')\n",
    "except HTTPError as e:\n",
    "    print(e) # null을 반환하거나, break 문을 실행하거나, 기타 다른 방법을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서버를 전혀 찾을 수 없거나 페이지가 다운됐을 때, URL에 오타가 있을 떄 urlopen은 URLError 예외를 발생힌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Server could not be found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, HTTPError, URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('https://pythonscrapingthisurlopendoesnotexist.com')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print('The Server could not be found!')\n",
    "else:\n",
    "    print(\"It Worked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
