{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_data's key:\n",
      " dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print(\"iris_data's key:\\n\", iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, pre\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'][:193] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target's name: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Target's name:\", iris_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성의 이름:\n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(\"특성의 이름:\\n\", iris_dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 타입: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"data의 타입:\", type(iris_dataset['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 크기: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"data의 크기:\", iris_dataset['data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 처음 다섯 행:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"data의 처음 다섯 행:\\n\", iris_dataset['data'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target의 타입: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"target의 타입:\", type(iris_dataset['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target의 크기: (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"target의 크기:\", iris_dataset['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타깃:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"타깃:\\n\", iris_dataset['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_dataset['data'], iris_dataset['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 크기: (112, 4)\n",
      "y_train 크기: (112,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train 크기:\", X_train.shape)\n",
    "print(\"y_train 크기:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test 크기: (38, 4)\n",
      "y_test 크기: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test 크기:\", X_test.shape)\n",
    "print(\"y_test 크기:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7.3 가장 먼저 할 일 : 데이터 살펴보기\n",
    "---\n",
    "> 머신러닝 모델을 만들기 전에 머신러닝이 없이도 풀 수 있는 문제는 아닌지, 혹은 필요한 정보가 누락되지는 않았는지 데이터를 조사해보는 것이 좋다.\n",
    "- 또한 데이터를 탐색하면서 비정상적인 값이나 특이한 값들을 찾을 수도 있다.\n",
    "- 예를 들어 붓꽃 데이터 중 일부는 센티미터가 아니고 인치로 되어 있을 수도 있다.\n",
    "- 실제로 데이터에 일관성이 없거나 이상한 값이 들어가 있는 경우가 종종 있다.\n",
    "\n",
    "## 산점도 - Scatter Plot\n",
    "---\n",
    "- 시각화는 데이터를 조사하는 아주 좋은 방법이다. 산점도가 그 중 하나이다.\n",
    "- 산점도는 데이터에서 한 특성을 x축에 놓고 다른 하나는 y축에 놓아 각 데이터 포인트를 하나의 점으로 나타내는 그래프이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mglearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5009813ca3b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmglearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# x_train 데이터를 사용해서 데이터프레임을 만든다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 열의 이름은 iris_dataset.feature_names에 있는 문자열을 사용한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miris_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miris_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mglearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mglearn\n",
    "# x_train 데이터를 사용해서 데이터프레임을 만든다.\n",
    "# 열의 이름은 iris_dataset.feature_names에 있는 문자열을 사용한다.\n",
    "iris_dataframe = pd.DataFrame(X_train, columns=iris_dataset.feature_names)\n",
    "# 데이터프레임을 사용해 y_train에 따라 색으로 구분된 산점도 행렬을 만든다.\n",
    "pd.plotting.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',\n",
    "                           hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mglearn\n",
      "  Downloading mglearn-0.1.9.tar.gz (540 kB)\n",
      "\u001b[K     |████████████████████████████████| 540 kB 11.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (1.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (3.3.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (0.24.1)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (1.2.4)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (8.2.0)\n",
      "Requirement already satisfied: cycler in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (0.10.0)\n",
      "Requirement already satisfied: imageio in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (2.9.0)\n",
      "Requirement already satisfied: joblib in /usr/local/anaconda3/lib/python3.8/site-packages (from mglearn) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/lib/python3.8/site-packages (from cycler->mglearn) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from matplotlib->mglearn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from matplotlib->mglearn) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from matplotlib->mglearn) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->mglearn) (2021.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from scikit-learn->mglearn) (1.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from scikit-learn->mglearn) (2.1.0)\n",
      "Building wheels for collected packages: mglearn\n",
      "  Building wheel for mglearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=9c946287291a496392e8a2a4dfbd12b0e5d7ccb06e33915ff5313be48532d025\n",
      "  Stored in directory: /Users/dead_line/Library/Caches/pip/wheels/87/75/37/404e66d0c4bad150f101c9a0914b11a8eccc2681559936e7f7\n",
      "Successfully built mglearn\n",
      "Installing collected packages: mglearn\n",
      "Successfully installed mglearn-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install mglearn"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
