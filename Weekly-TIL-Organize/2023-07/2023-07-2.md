# 2023-07-2(10~14)

---

# Spark UI를 보며 partition 최적화(집중력 최고, 재밌음)

> Spark UI를 보며 최적화를 잘 하려면 Spark의 내부 구조와 원리 및 처리 과정에 대해 깊이 이해해야 한다. (내가 부족해서 하는 소리다)

- 깨달은 점

    - S3(등의 저장소)에서 Parquet(등의 file)을 읽은 후 persist()를 하지 않으면 계속 읽으러 간다. (적어도 UI의 DAG Visualization에는 그렇게 나온다. 다음에 해당 작업의 상태가 Skipped되어 있는지 확인하자. Spark는 인메모리 기반이므로 데이터를 메모리에 올려두고 처리한다. 이 때 처리할 대상이 되는 데이터가 메모리에 올라가 있으면 처리 작업에서 Skipped된다.)

    - `persist()`를 제대로 사용하는 방법

        Spark의 `persist()`는 기존의 DataFrame을 변경하지 않고 새로운 DataFrame을 반환한다. 이 새로운 DataFrame은 원래 DataFrame을 메모리에 캐싱하는 특성을 가진다.

        `persist()`는 DataFrame을 메모리에 캐싱하여 여러 번 사용할 때 계산을 재사용하고, 불필요한 I/O를 방지하여 성능을 향상시키는 데 사용된ㄷ다. 이는 특히 같은 DataFrame을 여러 번 Action해야할 때 사용 시 매우 유용하다.

        따라서, `persist()`를 호출하면 반환된 DataFrame을 새로운 변수에 할당 후 사용해야 하며, 그렇지 않으면 캐싱된 DataFrame에 대한 참조를 잃으므로 `persist()`의 효과를 받지 못한다.

        아래의 예시는 잘못된 사용법과 옳은 사용법을 코드로 표현하였다.

        ```python
        ## 잘못된 사용법
        exist_df  # 기존 DataFrame
        exist_df.persist()  # 캐싱하였으나 새로운 DataFrame을 참조하지 않아 캐싱의 효과를 받지 못함
        
        exist_df.show()  # 캐싱되지 않은 원래의 DataFrame을 참조함
        
        ## 옳은 사용법
        exist_df  # 기존 DataFrame
        cached_df = exist_df.persist()
        
        cached_df.show()  # 제대로 캐싱된 DataFrame을 참조함
        ```

    - `persist()`를 제대로 사용하는 방법에 이어서 반대 메서드인 `unpersist()`에 대한 설명

        `unpersist()`는 DataFrame이나 캐싱된 데이터를 메모리에서 제거한다. 이 메서드는 해당 DataFrame 자체를 메모리에서 제거하는 것이 아닌, `persist()` 혹은 `cache() <- (persist()의 하위 호환에 해당하는 메서드)`에 의해 캐싱된 데이터만을 메모리에서 제거한다.

        `unpersist()`는 캐싱된 데이터를 메모리에서 제거하고 원래의 DataFrame을 반환한다. 하지만 이 반환값은 일반적으로 사용하지 않는다.

        `unpersist()`의 주요 목적은 캐싱된 DataFrame을 제거하여 메모리를 해제하는 것이기 때문이다. 따라서 **`unpersist()`는 메모리의 사용량을 줄이고자 할 때 주로 사용된다.**

    - `df.repartition(n).persist()`처럼 `repartition()``과 `persist()``가 함께 쓰일 때의 내부 동작

        `persist()`를 호출하면 해당 시점에서의 DataFrame의 상태를 메모리에 캐싱하게 된다. 만약 `df.repartition(50).persist()`와 같이 `repartition()` 이후에 `persist()`를 사용하면 repartitoin된 결과가 메모리에 캐싱되어 재사용할 수 있게 된다.

        하지만, `persist()`와 `repartition()` 모두 메모리를 사용하므로 사용 가능한 메모리 리소스를 고려하여 적절히 사용해야 한다. 

        또한 Spark의 Lazy Evaluation 특성으로 인해 `persist()`는 호출 이후 실제로 데이터가 메모리에 캐싱되는 시점은 Action이 호출될 때이다. (예: `count()`, `show()`, `collect()`)

    - Spark Cluster의 병렬성과 관련한 옵션들

        Spark Cluster는 병렬성을 제어하는 몇 가지의 유용한 설정을 가지고 있다.

        1. `spark.executor.cores`: 각 Executor가 사용하는 코어 수를 설정한다. 이 수가 늘어나면 각 Executor는 더 많은 Task를 동시에 처리할 수 있다. 하지만 이 수가 늘어나면 각 Task가 사용할 수 있는 CPU 리소스가 줄어든다.(당연하게도) 이 설정은 사용할 수 있는 코어의 총 갯수에 따라 달라진다.(이 설정을 했을 경우 내부적으로 어떻게 사용하는지 알아보고 싶다)
        2. `spark.default.parallelism`: Spark Job의 기본 병렬성 수준을 설정한다. 이 값은 Spark Cluster의 전체 작업량을 결정하는 데 사용된다.
        3. `spark.sql.shuffle.partitions`: Spark SQL에서 셔플 연산 이후 생성되는 파티션의 수를 제어한다. 이 값이 너무 작으면 셔플 이후 너무 많은 파티션이 생성될 수 있고, 너무 크면 큰 파티션이 생성될 수 있다. 따라서 어느 한 쪽으로 치우치지 않게 적절한 수를 설정하는 것이 좋다.
        4. `spark.dynamic.Allocation.enabled`: (더 알아보자)

    - Spark Cluster에서 사용하는 Worker Node의 Instance 최적화(**처리하는 데이터를 생각하고, 이 데이터에 최적화된 Instance를 설정할 수 있는 것이 엔지니어의 역할이다.**)

    

    



## Information

- SQL

    - `LIMIT`: 

        데이터개발팀장님께 bi-mart라 불리는 데이터베이스의 특정 테이블들에 대한 접근 권한을 팀 계정에 부여해달라는 요청을 했다. 이 때 권한들이 제대로 부여되었는지 확인하기 위해 평소와 같이 `SELECT * FROM [TABLE_NAME]`으로 조회가 가능한지 확인해보았다. 하지만 시간이 너무 오래 걸렸고, 특정 조건 없이 특정 테이블에 대한 전체 조회를 진행하면 DB에 부하가 걸린다는 것을 알았다. 이 때 사용하면 좋은 것이 바로 이 `LIMIT`이다. (예: `SELECT * FROM [TABLE_NAME] LIMIT 1 --1개의 레코드를 반환한다.`)

        `LIMIT`을 사용하면 반환되는 레코드의 수를 제한하여 서버에 부하를 해결하고 데이터의 반환시간을 크게 단축시킨다. 하지만 항상 DB의 부하를 줄이는 것은 아니다. `LIMIT`이 포함된 쿼리가 DB에서 효율적으로 실행되려면 적절한 인덱스가 있어야 한다. 그렇지 않으면, DB에서 발생하는 부하를 크게 줄이지 못할 수 있다.